---
作者: Caroline Mimbs Nyce
翻译: Claude 2.1
校对: LostAbaddon
tags:
  - AI
  - 翻译
  - 科学/科普
---
> Google，你确定非洲没有一个国家是以K开头的吗？

![插图：The Atlantic](_resources/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%AD%A3%E9%9D%A2%E4%B8%B4%E6%89%80%E6%9C%89%E4%BA%BA%E9%83%BD%E6%8B%85%E5%BF%83%E7%9A%84%E9%97%AE%E9%A2%98/2b9859467f93a1404a5f945d17d7a27a_MD5.png)

Google所拥有的知识总和到底有多么庞大，很难简单地用一两句话就说清楚。它在不断地扩张，无穷无尽。它是一张持续增长的巨网，由数以千亿计的网站组成，就是用10万部最贵的iPhone也装不下其中的数据。但是，此时此刻，我却可以这样说：Google都搞不清楚非洲是否有一个国家的名字是以K开头的。

我已经要求搜索引擎来找出这个国家了：“非洲有哪个国家是以K开头的？”作为回应，谷歌给了我一个“特色即时段落（featured snippet）”——用户可以直接在搜索结果词条上读到相关内容而无需导航到另一个网站——它的开头是这么说的：“虽然非洲有54个被认可的国家，但没有一个是以字母‘K’开头的。”

错到离谱。

然后它接着说：“最接近以‘K’音开头的国家是肯尼亚，但实际上只是发音为‘K’。能学到这一新奇的冷知识还挺有意思的。”

这段回答实在是太无厘头了，以至于如果我告诉你这段答案其实最初是源自ChatGPT的手笔，你大概也不会再感到任何惊讶了。你更可能感到惊讶的点，大概在于这么离谱的答案是怎么混进互联网权威知识库并成为一条“特色词条”的。

事实上，Google这样的搜索引擎是从Hacker News这个网站的用户帖子中抓取到这段文字的。Hacker News是一个讨论技术的在线留言板，那篇帖子则是在引用Emergent Mind网站上的另一篇帖子的内容，而后者的内容恰好是让人们更加了解AI——包括它的缺陷。在某个充满巧合的时刻，Google的爬虫爬取了这段文字，而后它的算法又恰好自动把帖子内容中聊天机器人所生成的无稽之谈作为事实记录了下来，并给了一个指向Hacker News讨论帖的链接。

无论用户偶遇这一“肯尼亚错误”的机会有多渺小，它都在事实上不止一次地产生了错误的影响：我上个月第一次看到这个肯尼亚错误是在记者Christopher Ingraham热传的推文里，而更早还在今年8月于Futurism网站上看到过。(当Ingraham和Futurism遭遇这一错误时，Google引用的还是那篇Emergent Mind上的原始帖子，而不是Hacker News上的引用。)

这基本上概括了Google目前所面临的致命挑战：公司已经迈进了生成式AI的新时代，它的搜索引擎算法已经复杂到无以复加，但是它所掌握的信息却可能会被无意义的、虚假的甚至荒谬的内容所劫持。类似特色词条这样的旧功能正在被有瑕疵的AI写作工具所生成的内容所污染；而它自己的生成式AI工具这样的新功能——Bard，有点像聊天机器人——也有可能正在生产有瑕疵的内容来污染别人。Google从来都不是完美的，但现在这种不完美更甚：对于想要从它获得清晰无误的事实的人来说，现在正是最不可靠的时刻。

在一份回应诸多类似质疑的公开声明中，Google公司的发言人表示：“我们打造搜索引擎的目的，是为了从可靠的信息源获取高质量的内容，尤其是在那些内容质量至关重要的话题上。”他还补充道：“当问题出现的时候，比如搜索结果反映出了网络上大规模存在的某种不准确性时，考虑到开放网络的规模之大以及我们每天会接触到的搜索数量之多，我们会尽力对这些有问题的结果进行人为改进。”

长久以来，人们一直对这类搜索引擎充满了信任与信赖，认为它是无所不知且不断更新的百科全书。在欣赏《星战前传1：幻影危机》时突然想知道贾贾·宾克斯的配音是谁？搜索引擎会告诉你是艾哈迈德·贝斯特。想不起来纽约喷气机队上一次赢超级碗是哪一年？搜索引擎会告诉你是1969年。以前，你得不得点进一个又一个独立的网站来阅读并获得这些问题的答案，而随着Google等搜索引擎的兴起，这么多年来我们一直都从它们所提供的“即时段落（snippet）”里直接获取所要的信息，附带还能看到信息来源的超链接，就像肯尼亚错误里我们所看到的那样。而如今，生成式AI让这一切更进一步，在我们看到搜索结果之前，搜索栏的下方已经出现了AI为我们量身打造的“原创答案”。在不久的将来，当你询问美国通胀率为何如此之高时，AI将告诉你答案，并给你一组能获取相关信息的链接。（你现在就可以体验Google的这一实验性功能，只需要加入Google的“实验性功能”计划就可以了。）  

其实早在生成式AI诞生之前很久，搜索引擎提供的结果中存在错误信息甚至虚假信息就已经是一个很现实的问题了。2017年时，The Outline就曾指出Google提供的一条搜索结果即时段落信誓旦旦地断言“巴拉克·奥巴马是美国国王”。

> 有兴趣的读者可以在这里看到这篇报道：
> https://theoutline.com/post/1192/google-s-featured-snippets-are-worse-than-fake-news

而肯尼亚错误这个例子则表示，AI生成的胡言乱语很可能骗过搜索引擎的算法，而一旦它们成功了，这些胡说八道就会堂而皇之地被算法奉上神坛，获得远高于其他搜索结果的VIP位置。

自从ChatGPT面世以来，专家们就一直在担心着这种情况：虚假的信息被光明正大地奉为事实，而我们完全发现不了这些其实是彻头彻尾的荒谬。华盛顿大学信息与计算机科学教授Chirag Shah告诉我，问题在于“信息呈现的方式，就是问题的答案”，“用户其实根本不关心信息的来源，搜索引擎直接提供给了你一个包含答案的段落，但如果这个段落是断章取义呢？”

Google对此持不同观点。负责领导该公司搜索质量团队的副总裁Pandu Nayak告诉我，设计即时段落的目的是为了帮助用户挖掘相关且高质量的结果。他认为，即时段落“通常能启发用户进一步”了解一个主题。对于Google有激励措施阻止用户离开搜索页的说法，他补充道：“我们并不希望人们一直停留在Google上，这不是我们的价值观。”他认为，说人们只想找到一个更广泛主题的单一事实后就直接关闭页面，是一种“谬论”。

尽管有大量病毒式传播的帖子在疯狂吐槽Google的肯尼亚错误，但相关结果依然能在Google的搜索结果中被看到。对此，Nayak说这是一个战略选择，而非真正的错误。如果一个即时段落违反了Google的相关政策，比如它包含了仇恨言论，那么Google会通过人为干预来限制它的出现；但如果即时段落只是提供了不正确的信息但并不违反任何政策且没造成任何伤害的话，那么公司并不会进行干预。Nayak说，公司的团队一直都在关注更大、更严重的潜在问题，以及算法是否可以通过恰当的训练来解决这些问题。  

搜索引擎优化（SEO）是一门大生意，因为在搜索引擎的结果页上占据有利位置可以带来巨大的网站流量与广告收入。如果Nayak是正确的，人们即便看到了即时段落也依然会点击相关链接，那么任何想通过搜索来获得点击量或收益的人都会充满了动力来利用这一点——甚至不惜让AI生成内容来攻占即时段落。Nayak告诉我，Google正计划像过去打击垃圾信息那样，积极打击AI生成的垃圾信息，并称搜索引擎已经成功避开了99%的垃圾信息。

就在Google与AI生成的垃圾话作斗争时，我们也不能忽视它自己产生AI垃圾话的风险。我一直在我的Chrome浏览器中试用Google的基于生成式AI的“搜索生成体验”，简称SGE。就如前文提到的那样，它会在搜索栏之下、搜索结果之前提供一份答案——只不过这次这份答案是由Google的AI编写的，而不是引自外部来源。

我最近就一则不痛不痒但我分外关注的故事询问了该工具：歌手Joe Jonas和演员Sophie Turner的离婚事件。当我问Google他们为何分手时，AI起初的表现还不错，引用了这对夫妇的官方声明。但随后它将《US Weekly》杂志的一则匿名消息来源作为事实转述给了我：“Turner说Jonas管控欲太强。”而事实上，Turner从未公开发表过这样的评论。该生成式AI还和肯尼亚错误产生了混响：“非洲没有一个国家是以字母‘K’开头的，但是肯尼亚是非洲的54个国家之一，开头发音是‘K’。”

结果就是，新技术让这个世界看起来更加困惑而不是减少困惑。“这是一个奇怪的世界，这些大公司认为他们只要在搜索结果的头上淋上点儿这种AI生成的泔水，就能确保搜索体验的质量万无一失，”西北大学传播研究与计算机科学教授Nicholas Diakopoulos告诉我，“每当我发现自己开始阅读这些AI垃圾时，我就会停下来。我想，打住，Nick，你不能相信这些。”

Google则表示，该工具仍处于测试阶段。Nayak承认，一些人可能会“肤浅地”对SGE提供的结果照单全收，但他认为更多的人会选择由此深入调查下去。Nayak还说，公司目前不允许用户在某些可能含有错误信息的敏感领域触发该工具。例如，当我询问人们是否应该戴口罩时，它并未生成答案。

对于科技公司应该如何减少在搜索结果中过度依赖AI而带来的潜在风险，我所采访的专家们提供了几点建议。

首先，科技公司应该让生成式AI更透明。Diakopoulos建议它们可以公布人们就重要主题提问时搜索引擎所提供的“事实”的质量信息。它们可以使用一种被称为“检索增强生成（RAG）”的技术，这种技术会指示AI交叉检查其所提供的答案与其他地方发表的内容，从根本上帮助AI进行自我事实核查。(Google的发言人说他们的搜索引擎已经使用类似技术来改进其搜索结果了。)科技公司可以向研究人员开放其工具以进行压力测试。或者，它们也可以增设人工监管，甚至可以投资事实核查工作相关的项目。

然而，事实核查本身就是一个充满挑战的难题。

今年1月，Google的母公司Alphabet裁减了约6%的员工。上个月该公司再次裁减了至少40个谷歌新闻部的岗位。这正是过去与专业事实核查组织合作、将事实核查结果引进到搜索结果中的团队。目前尚不清楚确切被裁的人员和他们的工作职责——The Verge的Alex Heath报道称，高管也在被裁名单中，而Google拒绝向我提供更多信息。这无疑表明，Google在打造其生成式AI工具的同时，并未加大对事实核查的投入。

一位发言人在相关声明中宣称，Google“坚定地致力于构建一个充满活力的信息生态系统，而新闻正是长期投资的一部分......这些变化对我们的错误信息处理和信息质量工作没有任何影响。”在后续消息中，另一位发言人还提到了更多的其他更新，比如能为搜索结果提供更丰富上下文的图片核查工具。即便如此，Nayak也承认，对Google这种体量的平台进行人工事实核查是一项异常艰巨的任务。他告诉我，每天有15%的搜索请求是搜索引擎前所未见的。“考虑到这种规模和新颖性，我们不可能手工整理所有结果。”创建一个既庞大又自动化同时还高度准确的知识百科似乎过于缥缈了，但这正是Google正在采取的战略方向。

也许未来这些工具会变得更加智能，能够自我事实核查。但在此之前，事情可能会变得更加复杂。本周，我突发奇想地决定询问Google的生成式搜索工具我的丈夫是谁（我未婚，但在Google中输入我的名字时它通常会建议搜索“Caroline Mimbs Nyce husband”）。该机器人告诉我，我嫁给了自己的叔叔，作为佐证它链接到我祖父的讣告——但实际上讣告中并未提到我嫁给了叔叔。

Google的一名代表告诉我，这是一个典型的“错误前提（false premise）”搜索的案例，而众所周知，这种搜索方法会引起算法崩溃。她进一步争辩道，如果她想约我出去，她不会仅仅满足于搜索引擎所提供的AI生成的回复，而会点击链接进行事实核查。

让我们一起祈祷其他用户也能像她这样对所见内容充满怀疑的态度吧。